---
title: "Compute resources"
sidebarTitle: "Resources"
---

Follow the instructions in this [doc](/production/deploying-to-cloud/using-terraform) to deploy
Mage tool to production environment. When running the Mage tool in production,
you can customize the compute resource in the following ways:

## 1. Customize the compute resource of the Mage web service

Mage web serivce is responsbile for running Mage web backend, scheduler service
and local block executions. You can customize the CPU and memory of the Mage web
service by updating the Terraform variables and then running `terraform apply`

- AWS: Update the `ecs_task_cpu` and `ecs_task_memory` variables in the
  [`mage-ai-terraform-templates/aws/variables.tf`](https://github.com/mage-ai/mage-ai-terraform-templates/blob/master/aws/variables.tf)
  file.
- GCP: Update the `container_cpu` and `container_memory` variables in the
  [`mage-ai-terraform-templates/gcp/variables.tf`](https://github.com/mage-ai/mage-ai-terraform-templates/blob/master/gcp/variables.tf)
  file.

## 2. Set executor type and customize the compute resource of the Mage executor

Mage provides multiple executors to execute blocks. Here are the available executor types:
* `local_python`
* `ecs`
* `gcp_cloud_run`
* `azure_container_instance`
* `k8s`

Mage uses `local_python` executor type by default. If you want to specify another executor_type as the default executor type for blocks,
you can set the environment variable `DEFAULT_EXECUTOR_TYPE` to one executor type mentioned above.

### Local python executor

Local python exeuctors are running within the same container of Mage web
service. You can customize the compute resource with the same way mentioned in
the
[Customize the compute resource of the Mage web service](#customize-the-compute-resource-of-the-mage-web-service)
section.

### Kubernetes executor

If your Mage app is running in a Kubernetes cluster, you can execute the blocks in separate Kubernetes pods with Kubernetes executor.

To configure a pipeline block to use Kubernetes executor, you simply just need to update the `executor_type` of the block to `k8s` in pipeline's metadata.yaml:

```yaml
blocks:
- uuid: example_data_loader
  type: data_loader
  upstream_blocks: []
  downstream_blocks: []
  executor_type: k8s
  ...
```
By default, Mage uses `default` as the Kubernetes namespace. You can customize the namespace by setting the `KUBE_NAMESPACE` environment variable.

There're two ways to customize the compute resource for Kubernetes executor:

1. Add the `executor_config` at block level in pipeline's metadata.yaml file. Example config:
    ```yaml
    blocks:
    - uuid: example_data_loader
      type: data_loader
      upstream_blocks: []
      downstream_blocks: []
      executor_type: k8s
      executor_config:
        resource_limits:
          cpu: 1000m
          memory: 2048Mi
        resource_requests:
          cpu: 500m
          memory: 1024Mi
    ```
2. Add the `k8s_executor_config` to project's metadata.yaml. This `k8s_executor_config` will apply to all the blocks that use k8s executor
in this project. Example config:
    ```yaml
    k8s_executor_config:
      resource_limits:
        cpu: 1000m
        memory: 2048Mi
      resource_requests:
        cpu: 500m
        memory: 1024Mi
    ```
If you want to use GPU resource in your k8s executor, you can configure the GPU resource in the `k8s_executor_config` like
```yaml
k8s_executor_config:
  resource_limits:
    gpu-vendor.example/example-gpu: 1 # requesting 1 GPU
```
Please make sure the [GPU driver](https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/#using-device-plugins)
is installed and run on your nodes to use the GPUs.

### AWS ECS executor

You can choose to launch separate AWS ECS tasks to executor blocks by specifying
block executor_type to be `ecs` in pipeline's metadata.yaml file.

There're 2 ways to customize the compute resource of ECS executor,
1. Update `cpu` and `memory` the `ecs_config` in project's metadata.yaml file. Example config:
    ```yaml
    ecs_config:
      cpu: 1024
      memory: 2048
    ```
2. Add the `executor_config` at block level in pipeline's metadata.yaml file. Example config:
    ```yaml
    blocks:
    - uuid: example_data_loader
      type: data_loader
      upstream_blocks: []
      downstream_blocks: []
      executor_type: ecs
      executor_config:
        cpu: 1024
        memory: 2048
    ```

### GCP Cloud Run executor

If your Mage app is deployed on GCP, you can choose to launch separate GCP Cloud Run jobs to execute blocks.

How to configure pipeline to use GCP cloud run executor:
1. Update Project's metadata.yaml
```yaml
gcp_cloud_run_config:
  path_to_credentials_json_file: "/path/to/credentials_json_file"
```

2. Update the `executor_type` of block to `gcp_cloud_run` in pipeline's metadata.yaml:

```yaml
blocks:
- uuid: example_data_loader
  type: data_loader
  upstream_blocks: []
  downstream_blocks: []
  executor_type: gcp_cloud_run
  ...
```
Customizing compute resource for GCP Cloud Run executor is coming soon.

### Azure Container Instance executor

If your Mage app is deployed on Microsoft Azure with Mage's [terraform scripts](https://github.com/mage-ai/mage-ai-terraform-templates/tree/master/azure),
you can choose to launch separate Azure containce instances to execute blocks.

How to configure pipeline to use Azure Container Instance executor:
1. Update Project's metadata.yaml
```yaml
azure_container_instance_config:
  cpu: 1
  memory: 2
```

2. Update the `executor_type` of the block to `azure_container_instance` in pipeline's metadata.yaml and specify `executor_config` optionally.
The block level executor_config will override the global executor_config.

```yaml
blocks:
- uuid: example_data_loader
  type: data_loader
  upstream_blocks: []
  downstream_blocks: []
  executor_type: azure_container_instance
  executor_config:
    cpu: 1
    memory: 2
  ...
```

### PySpark executor

If the pipeline type is "pyspark", we use PySpark exeuctors for pipeline and
block executions. You can customize the compute resource of PySpark exeuctor by
updating the instance types of `emr_config` in project's metadata.yaml file.

Example config:

```yaml
emr_config:
  ec2_key_name: "xxxxx"
  master_instance_type: "r5.2xlarge"
  slave_instance_type: "r5.2xlarge"
```
