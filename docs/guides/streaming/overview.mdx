---
title: "Overview"
---

## Introduction

Each streaming pipeline has three components:
- Source: The 
- Transformer: Write python code to transformt the message before writing to destination
- Sink (destination): 


## Supported sources
- [Azure Event Hub](https://github.com/mage-ai/mage-ai/blob/master/mage_ai/data_preparation/templates/data_loaders/streaming/azure_event_hub.yaml)
- [Kafka](sources/kafka)
- [Kinesis](sources/kinesis)
- [RabbitMQ](streaming-pipeline-rabbitmq)

## Support sinks (destinations)

- [Kinesis](destinations/kinesis)
- [Opensearch](destinations/opensearch)
- [Redshift (via Kinesis)](destinations/redshift)


## Test pipeline execution
After finishing configuring the streaming pipeline, you can click the button `Execution pipeline` to test streaming pipeline execution.